{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduction Operations in Numpy Arrays\n",
    "\n",
    "Numpy arrays have become inexpensible in the world of data science. They offer a wide range of functions which are encountered most often when dealing with data. One such family of functions is the family of reduction operations. Eponymously, reduction operations are the ones which reduce the number of elements in an array. \n",
    "\n",
    "Just by reading through the definition, we can't gauge the significance of these operations. Let me give a list of the functions we're going to look at, then the usability of these functions will become very clear. \n",
    "\n",
    "- descriptive stats - sum, mean, std, min, max, median\n",
    "- argmax\n",
    "- argmin\n",
    "- reduce\n",
    "\n",
    "So, let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like it says, it sums up the elements of an array. When we're dealing with a one dimensional array, it's not anything great, it's just a simple addition of a few numbers thrown at a computer.\n",
    "\n",
    "But when we go to higher dimensions, we can see the real power of numpy. We can sum along any given axes of an object. Consider a 2-Dimensional array/matrix for example. \n",
    "\n",
    "<img src=\"https://media.geeksforgeeks.org/wp-content/uploads/sum-of-each-row-and-column.jpg\" width=\"40%\">\n",
    "\n",
    "Many real world structures/tabular data problems are processed in pandas dataframe which is built on top of numpy arrays. Typically, the rows are records of an individual datapoint and the columns are the features of a record. When we want to get an idea of the distribution of features we can use reduction operations like sum over individual axes (particularly the columns). Here's an example of the same below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39 34 45 30]\n",
      " [47 46 47 38]\n",
      " [39 30 40 38]\n",
      " [34 49 46 34]\n",
      " [45 41 41 31]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(10)\n",
    "scores = np.random.randint(30, 50, (5, 4))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say the values above are the scores of 5 students in 4 subjects. Here, rows represent students(records) and columns represent marks in a subject(features). We can see the sum of scores of each student by summing over the rows. We can see the sum of scores per subject by summing over the columns. Here's how we can do the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([204, 200, 219, 171])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summing over the columns/features\n",
    "scores.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([148, 178, 147, 163, 158])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summing over the rows/records\n",
    "scores.sum(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's say we wanted to focus on the average marks scored by a student, we can reduce the scores array using the mean function in numpy as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([37.  , 44.5 , 36.75, 40.75, 39.5 ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average score per student\n",
    "scores.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([40.8, 40. , 43.8, 34.2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average score per subject\n",
    "scores.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also focus on the standard deviation of marks scored by students. Standard Deviation is intuitively speaking how bound or spread the distribution of the marks is from the mean score of the students. It measures how dispersed the data is from the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.47706773014274"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the spread of average marks in the 4 subjects\n",
    "np.std(scores.mean(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8346075566116733"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the spread of average marks of students in the class\n",
    "np.std(scores.mean(axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the highest and lowest scores which a student has secured using the min and max functions respectively. They too are as simple to use as the above ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([34, 30, 40, 30])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the lowest score secured in every subject\n",
    "scores.min(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30, 38, 30, 34, 31])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the lowest score secured by each student\n",
    "scores.min(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([47, 49, 47, 38])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the highest score secured in every subject\n",
    "scores.max(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([45, 47, 40, 49, 45])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the highest score secured by each student\n",
    "scores.max(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the we have always specified the axis argument until now, telling numpy explicitly that we want to reduce along that dimension. Sometimes you're interested in global reduction, i.e. reduce the entire matrix to a single value. Let's say you wanted to find the sum of scores of all students in all subjects or, you wanted to find the mean score across all students in all subjects. This can be done by ommitting the axis argument altogether. This will then perform reduction across the entire array or matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The global sum of scores is:     794\n",
      "The global mean of scores is:    39.7\n",
      "The global minimum of scores is: 30\n",
      "The global maximum of scores is: 49\n"
     ]
    }
   ],
   "source": [
    "# Reducing globally\n",
    "print(f\"The global sum of scores is:     {scores.sum()}\")\n",
    "print(f\"The global mean of scores is:    {scores.mean()}\")\n",
    "print(f\"The global minimum of scores is: {scores.min()}\")\n",
    "print(f\"The global maximum of scores is: {scores.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two more reduction operations which in addition to the above ones which are of great significance especially in Machine Learning and Deep Learning.\n",
    "\n",
    "## argmax & argmin \n",
    "\n",
    "Given an array it finds out the index of the maximum or minimum element along a given dimension. Let us consider using the above example itself. Suppose we wanted to find out which student out of the five students scored highest in subject one. We can get the scores for subject one and do an argmax on the same to find this out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [34 46 30 49 41]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject1scores = scores[:, 1]\n",
    "print(f\"Scores: {subject1scores}\")\n",
    "subject1scores.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since indexing starts at 0, we can see from the scores above that 4th student i.e. the 3rd index is where the scores are highest. \n",
    "\n",
    "Consider that we wanted to find out which student got the lowest marks in subject one. We can do an argmin on the same array to figure that out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [34 46 30 49 41]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject1scores = scores[:, 1]\n",
    "print(f\"Scores: {subject1scores}\")\n",
    "subject1scores.argmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find out the same for all the subjects using the entire array and specifying the reduction dimension along the axis. Since we want to reduce across the scores, we'll specify axis = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 1, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Student who scored max in each of the subjects\n",
    "scores.argmax(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 2, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Student who scored the least in each of the subjects\n",
    "scores.argmin(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can conversely find out which subject did every student performed the best or the worst in by specifying the axis accordingly, we'll specify axis = 1 for this case and this is how it appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 1, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The subject which each of the five students topped in\n",
    "scores.argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 1, 0, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The subject which each of the five students struggled the most with\n",
    "scores.argmin(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In classification tasks in Machine Learning and Deep Learning applications, we always get a probability distribution or likelihood scores of every class for a given input. argmax() function helps to find out the most likely class for that input.\n",
    "\n",
    "\n",
    "> In nearest neighbour search application for eg. picking items similar to a given input item, a distance matrix is calculated and argmin() function helps to find out the nearest neighbours because we're looking to minimize the distances of the neighbours from the given input item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reduce & accumulate operations\n",
    "\n",
    "Numpy provides this function in order to reduce an array with a particular operation. The way these functions work are they repeatedly apply the operation over all the elements of an array until only a single element remains. \n",
    "\n",
    "The key difference between the two is that reduce function stores only the final result whereas the accumulate function stores all the middle stages of computation as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "[ 1  3  6 10 15 21]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1,2,3,4,5,6])\n",
    "print(np.add.reduce(x))\n",
    "print(np.add.accumulate(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions help us in case where we have to perform cumulative operations for eg. \n",
    "- Finding out the cumulative distribution of a feature.\n",
    "- Creating elbow charts to determine how many significant components to keep in Principal Component Analysis (a method used for dimensionality reduction in ML)\n",
    "\n",
    "In this post, we studied about reduction operations in numpy which are very handy in many ML/DL/Data Science operations in general. In our next post we shall talk about some advanced operations in numpy which are commonplace and inevitable to Data Scientists.\n",
    "\n",
    "## References\n",
    "1. [Array Image](https://www.geeksforgeeks.org/)\n",
    "2. [Array Computations](https://jakevdp.github.io/PythonDataScienceHandbook/02.03-computation-on-arrays-ufuncs.html)\n",
    "3. [Matrix Rain Image](http://www.teachmeidea.com/2018/09/how-to-build-matrix-rain-in-java.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:okkular] *",
   "language": "python",
   "name": "conda-env-okkular-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
